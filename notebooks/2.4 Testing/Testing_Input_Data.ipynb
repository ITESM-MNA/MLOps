{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed only for the purpose of the notebook\n",
    "!pip install ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple setup in the data\n",
    "iris_df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview of the first 5 rows in the data\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple counts in our target variable\n",
    "iris_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the classes to build a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        # Each value is None when we instantiate the class\n",
    "        self.X_train, self.X_test, self.y_train, self.Y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Loading the dataset, and make the train, test, split.\"\"\"\n",
    "        dataset = datasets.load_iris()\n",
    "        \n",
    "        # Removing the units (cm) from the headers\n",
    "        self.feature_names = [fn[:-5] for fn in dataset.feature_names]\n",
    "        self.frame = pd.DataFrame(dataset.data, columns=self.feature_names)\n",
    "        self.frame['target'] = dataset.target\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.frame[self.feature_names], self.frame.target, test_size=0.65, random_state=42)\n",
    "        \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        \n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        return self.model.predict(input_data)\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Execution method for running the pipeline several times.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = SimplePipeline()\n",
    "pipeline.run_pipeline()\n",
    "accuracy_score = pipeline.get_accuracy()\n",
    "print(f'The Accuracy of the model is: {accuracy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the schema\n",
    "iris_schema = {\n",
    "    'sepal length': {\n",
    "        'range': {\n",
    "            'min': 4.0,\n",
    "            'max': 8.0\n",
    "        },\n",
    "        'dtype': float,\n",
    "    },\n",
    "    'sepal width': {\n",
    "        'range': {\n",
    "            'min': 1.0,\n",
    "            'max': 5.0\n",
    "        },\n",
    "        'dtype': float,\n",
    "    },\n",
    "    'petal length': {\n",
    "        'range': {\n",
    "            'min': 1.0,\n",
    "            'max': 7.0\n",
    "        },\n",
    "        'dtype': float,\n",
    "    },\n",
    "    'petal width': {\n",
    "        'range': {\n",
    "            'min': 0.1,\n",
    "            'max': 3.0\n",
    "        },\n",
    "        'dtype': float,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture\n",
    "def pipeline():\n",
    "    pl = SimplePipeline()\n",
    "    pl.run_pipeline()\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_input_data_ranges(pipeline):\n",
    "    # Getting the maximum and minimum values for each column\n",
    "    max_values = pipeline.frame.max()\n",
    "    min_values = pipeline.frame.min()\n",
    "    \n",
    "    # Ensuring that the maximum and minimum values fall into the expected range\n",
    "    for feature in pipeline.feature_names:\n",
    "        assert max_values[feature] <= iris_schema[feature]['range']['max']\n",
    "        assert min_values[feature] >= iris_schema[feature]['range']['min']\n",
    "\n",
    "def test_input_data_types(pipeline):\n",
    "    # Getting the data types from each column\n",
    "    data_types = pipeline.frame.dtypes\n",
    "    \n",
    "    # Testing compatibility between data types\n",
    "    for feature in pipeline.feature_names:\n",
    "        assert data_types[feature] == iris_schema[feature]['dtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LetÂ´s make the test fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_input_data_ranges(pipeline):\n",
    "    max_values = pipeline.frame.max()\n",
    "    min_values = pipeline.frame.min()\n",
    "    \n",
    "    for feature in pipeline.feature_names:\n",
    "        # We change the values so the new ones are not the same as those we have already in the schema\n",
    "        assert max_values[feature] < 0  # This will make the test fail\n",
    "        assert min_values[feature] > 1000  # This one as well\n",
    "\n",
    "def test_input_data_types(pipeline):\n",
    "    # Getting the data types from each column\n",
    "    data_types = pipeline.frame.dtypes\n",
    "    \n",
    "    # Making comparissons between data types\n",
    "    for feature in pipeline.feature_names:\n",
    "        assert data_types[feature] != iris_schema[feature]['dtype']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
